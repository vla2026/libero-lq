<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>LIBERO-LQ</title>
  <link rel="icon" href="./figs/logo.png" type="image/png">
  <!-- <link rel="icon" href="./figs/logo.svg" type="image/svg+xml"> -->

  <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
  <link rel="stylesheet" href="style.css">

  <!-- MathJax Configuration for LaTeX Rendering -->
  <script>
  window.MathJax = {
    tex: { inlineMath: [['\\(', '\\)'], ['$', '$']] },
    svg: { fontCache: 'global' }
  };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>

</head>
<body>
  <div class="toc">
    <h3>Content</h3>
    <hr>
    <ul>
      <li><a href="#abstract">Abstract</a></li>

      <li><a href="#motivation">Why VLA Latency Matters</a></li>

      <li><a href="#latency">Latency</a></li>
        <li class="toc-subsection"><a href="#Latency">Latency-Aware Simulation</a></li>
        <li class="toc-subsection"><a href="#Execution">Policy Execution Protocol</a></li>

      <li><a href="#Quality">Quality</a></li>
        <li class="toc-subsection"><a href="#InferenceLatency">Inference Latency</a></li>
        <li class="toc-subsection"><a href="#EndToEndTaskCompletionTime">End-to-End Task Completion Time</a></li>
        <li class="toc-subsection"><a href="#Jerk">Jerk</a></li>
        <li class="toc-subsection"><a href="#Stability">Stability</a></li>
        <li class="toc-subsection"><a href="#TrajectoryEfficiency">Trajectory Efficiency</a></li>
        <li class="toc-subsection"><a href="#JointRotationEfficiency">Joint Rotation Efficiency</a></li>
        <li class="toc-subsection"><a href="#EnergyEfficiency">Energy Efficiency</a></li>

      <li><a href="#deploy-in-real-fail">Experimental Results</a></li>
      <!-- <li><a href="#acknowledgements">Acknowledgements</a></li> -->
    </ul>
  </div>

  <div class="main-content">
    <div class="hero-text">LIBERO-LQ</div>
    <div class="sub-hero-text">A Latency- and Quality-Aware Benchmark for Vision-Language-Action Models</div>

    <!-- Add Authors -->
    <div class="authors">
      <!-- <a href="https://allshire.org/" target="_blank">Arthur Allshire*</a>, <a href="https://hongsukchoi.github.io/" target="_blank">Hongsuk Choi*</a>, <a href="https://www.junyi42.com/" target="_blank">Junyi Zhang*</a>, <a href="https://mcallisterdavid.com/" target="_blank">David McAllister*</a>, <a href="https://antoniomacaronio.github.io/personal-website/#/home/" target="_blank">Anthony Zhang</a>, <a href="https://chungmin99.github.io/" target="_blank">Chung Min Kim</a>,<br>
      <a href="https://people.eecs.berkeley.edu/~trevor/" target="_blank">Trevor Darrell</a>, <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank">Pieter Abbeel</a>, <a href="https://people.eecs.berkeley.edu/~malik/" target="_blank">Jitendra Malik</a>, <a href="https://people.eecs.berkeley.edu/~kanazawa/" target="_blank">Angjoo Kanazawa.</a>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(*:equal contribution)
      <span class="affiliation">University of California, Berkeley</span> -->
      Anonymous Authors
    </div>
    <!-- End Authors -->

    <!-- use the video ./figs/videomimic_teaser.mp4 -->
    <!-- <video id="teaser-video" src="./figs/lacy_main.mp4" width="100%" height="100%" controls muted playsinline autoplay></video> -->
    <!-- Caption for Figure 1 (Teaser Video) -->
    <!-- <p class="figure-caption">
        <b>LACY (Language-Action CYcle)</b> enables bidirectional grounding between language and action for robotic manipulation through a self-improving loop of three tasks: language-to-action (L2A), action-to-language explanation (A2L), and language-consistency verification (L2C).
    </p> -->

    <!-- Add Quick Links Here -->
    <div class="quick-links">
      <!-- <a href="./VideoMimic.pdf" target="_blank">[pdf]</a> -->
      <!-- <a href="https://arxiv.org/abs/2511.02239" target="_blank">[arxiv]</a> -->
      <!-- <a href="https://github.com/hongsukchoi/VideoMimic">[code]</a>  -->
      <!-- <a href="#gallery-section-anchor">[gallery]</a> -->
      <!-- <a href="https://youtu.be/UfWNIXBRCHc" target="_blank">[video]</a> -->
    </div>
    
    <!-- 1. ABSTRACT -->
    <div class="tagline" id="abstract">Abstract.</div>


    <div class="section">
        Vision-Language-Action (VLA) models have shown strong performance on robotic manipulation tasks through large-scale multimodal pre- training. 
        However, existing benchmarks typically assume negligible inference latency and rely primarily on binary success metrics, limiting their ability to evaluate deployment-relevant execution behavior. 
        We introduce LIBERO-LQ, a Latency- and Quality-aware benchmark for evaluating VLA models under realistic execution constraints. 
        LIBERO-LQ decouples policy inference from environment stepping, enabling simulated execution to progress during non-negligible inference latency and supporting systematic evaluation of synchronous and asynchronous execution paradigms under identical latency conditions. 
        Beyond task success and completion time, LIBERO-LQ incorporates a suite of trajectory-level, non-functional metrics that capture execution quality, including smoothness, stability, efficiency, and energy consumption. 
        Through experiments on representative VLA models, we show that latency-aware and quality-oriented evaluation exposes substantial differences in execution robustness and trajectory quality that are obscured under conventional synchronous evaluation.
    </div> 

    <!-- 2. MOTIVATION -->
    <div class="tagline" id="motivation">Why VLA Latency Matters</div>

    <a id="figure-1-img" href="figs/controlstack.png" download="controlstack.png">
      <img src="figs/controlstack.png" alt="controlstack">
    </a>
    <!-- Caption for Figure 1 -->
    <p class="figure-caption">
      <b>Execution pipeline of a Vision-Language-Action (VLA) system under realistic deployment conditions.</b> 
    </p>

    <div class="section">
      High-frequency sensing and low-level control operate continuously, while VLA policy inference runs at a much lower rate and updates position targets asynchronously. 
      During inference latency, the robot continues executing previously issued commands via the low-level controller, resulting in decoupled policy computation and control execution. 
      This mismatch is typically ignored in existing evaluation protocols.
    </div> 

    <!-- 3. LATENCY -->
    <div class="tagline" id="latency">Latency</div>

    <!-- 3.1 Latency-Aware Execution Model. -->
    <div class="section-subtitle" id="Latency">1. Latency-Aware Simulation.</div>

    <a id="figure-2-img" href="figs/comparision.png" download="comparision.png">
      <img src="figs/comparision.png" alt="Comparison between between existing benchmarks and LIBERO-LQ">
    </a>
    <p class="figure-caption">
      <b>Comparison between conventional VLA evaluation and our latency-aware execution model.</b>
    </p>

    <div class="section">
      <b>Left:</b> Traditional evaluation tightly couples inference and environment stepping, implicitly assuming zero simulated inference latency \( \Delta t^{\text{sim}}_{\text{inf}} = 0 \). 
      <b>Right:</b> Our approach decouples inference from environment stepping by explicitly injecting simulated inference latency. 
      During inference, the simulator advances via repeated <code>env.step</code> calls using a synchronous or asynchronous execution protocol, 
      where the number of steps \(N\) is determined by \( \Delta t^{\text{sim}}_{\text{inf}} \).
    </div>

    <!-- 3.2 Policy Execution Protocol. -->
    <div class="section-subtitle" id="Execution">2. Policy Execution Protocol.</div>

    <a id="figure-2-img" href="figs/sync_vs_async.png" download="sync_vs_async.png">
      <img src="figs/sync_vs_async.png" alt="Policy execution protocol">
    </a>
    <p class="figure-caption">
      <b>Comparison of synchronous and asynchronous policy execution under inference latency. </b>
      Each row illustrates action chunks produced at successive policy steps, while shaded regions indicate control timesteps. 
      <b>(a) Synchronous execution</b> blocks policy updates during inference, causing the robot to reuse the last available action chunk and exhibit stop-and-go behavior. 
      <b>(b) Asynchronous execution</b> decouples inference from execution by continuously consuming actions from an execution buffer, allowing new action chunks to replace future commands without stalling execution. 
      This visualization highlights how inference latency induces temporal misalignment and affects trajectory continuity under different execution paradigms.
    </p>

    <div class="section">
      <b>(a) Synchronous execution</b> blocks policy updates during inference, causing the robot to reuse the last available action chunk and exhibit stop-and-go behavior. 
      <b>(b) Asynchronous execution</b> decouples inference from execution by continuously consuming actions from an execution buffer, allowing new action chunks to replace future commands without stalling execution. 
      This visualization highlights how inference latency induces temporal misalignment and affects trajectory continuity under different execution paradigms.
    </div>

    <!-- 4 Quality Metrics. -->
    <div class="section" id="Quality">Quality.</div>

    <a id="figure-3-img" href="figs/overview.png" download="overview.png">
      <img src="figs/overview.png" alt="Overview of LIBERO-LQ">
    </a>
    <p class="figure-caption">
      <b>Overview of LIBERO-LQ.</b> 
    <div class="section">
      Existing robotic manipulation benchmarks primarily evaluate policies using functional metrics such as binary task success. 
      While effective for measuring task completion, such metrics provide limited insight into execution behavior and deployment-relevant performance.
      To address this limitation, we include several non-functional metrics, which characterize execution quality, efficiency, and robustness.
    </div> 

    <!-- 4.1 Inference Latency -->
    <div class="section-subtitle" id="InferenceLatency">Inference Latency.</div>
    
    <div class="section">
    We distinguish between <b>real inference latency</b> \( \Delta t^{\text{real}}_{\text{inf}} \), which measures the wall-clock time
    required for model inference on a given observation, and <b>simulated inference latency</b> \( \Delta t^{\text{sim}}_{\text{inf}} \), which is an explicitly injected delay during simulation.
    The simulated latency is treated as an experimental variable and determines how long high-level actions are held while the simulator continues to advance.
    </div> 

    <!-- 4.2 End-to-End Task Completion Time -->
    <div class="section-subtitle" id="EndToEndTaskCompletionTime">End-to-End Task Completion Time.</div>
    
    <div class="section">
    We define the end-to-end task completion time $T$ as the total wall-clock time required to complete a task episode, including both policy inference and action execution.
    This metric captures the cumulative effect of inference latency and execution semantics over the entire task.
    </div> 

    <!-- 4.3 Jerk. -->
    <div class="section-subtitle" id="Jerk">Jerk.</div>
    
    <div class="section">
    <p>
To quantify trajectory smoothness, we measure <em>jerk</em>, defined as the third time derivative of the end-effector position, which captures abrupt changes in acceleration and is a standard
indicator of motion smoothness in robotic manipulation.
Let \( \mathbf{p}_t \in \mathbb{R}^3 \) denote the end-effector position at timestep \( t \), sampled at a uniform interval \( \Delta t \).
We approximate the jerk vector using a third-order finite difference:
</p>

<p class="math-display">
\[
\mathbf{j}_t \approx
\frac{
\mathbf{p}_t
- 3\mathbf{p}_{t-1}
+ 3\mathbf{p}_{t-2}
- \mathbf{p}_{t-3}
}{
\Delta t^3
}.
\]
</p>

<p>
Trajectory smoothness is then quantified by the average jerk norm over the rollout:
</p>

<p class="math-display">
\[
J
=
\frac{1}{T - 3}
\sum_{t=4}^{T}
\lVert \mathbf{j}_t \rVert_2,
\]
</p>

<p>
where \( T \) denotes the trajectory length.
Lower jerk norm values correspond to smoother and more stable motion, while higher values
indicate abrupt or oscillatory behavior.
</p>

    <!-- 4.4 Stability -->
    <div class="section-subtitle" id="Stability">Stability.</div>
    
    <div class="section">
    <p> We measure stability by the average deviation of the end-effector position from its mean over a short temporal window of the last \( K \) steps: </p>

    <p class="math-display">
    \[
    \bar{\mathbf{p}}
    =
    \frac{1}{K}
    \sum_{i=T-K+1}^{T}
    \mathbf{p}_i,
    \quad
    \text{EE-Osc}
    =
    \frac{1}{K}
    \sum_{i=T-K+1}^{T}
    \left\|
    \mathbf{p}_i - \bar{\mathbf{p}}
    \right\|_2
    \]
    </p>

<p>
where \( \mathbf{p}_i \in \mathbb{R}^3 \) denotes the end-effector position at timestep \( i \).
Higher EE-Osc indicates increased oscillatory behavior during task execution, often arising from latency-induced control inconsistencies.
</p>

    </div> 

    <!-- 4.5 Trajectory Efficiency -->
    <div class="section-subtitle" id="TrajectoryEfficiency">Trajectory Efficiency.</div>
    
    <div class="section">
    <p> We assess trajectory efficiency by the total trajectory length required to successfully complete the task.
        Since the minimal feasible trajectory length depends on task geometry and goal configuration, efficiency is evaluated via relative, within-task comparisons among successful trials. </p>

    </div> 

    <!-- 4.6 Joint Rotation Efficiency -->
    <div class="section-subtitle" id="JointRotationEfficiency">Joint Rotation Efficiency.</div>
    
    <div class="section">
    <p>
We measure joint rotation efficiency by quantifying the total amount of joint motion executed over a trajectory.
Let \( \boldsymbol{\theta}_t \in \mathbb{R}^N \) denote the vector of joint angles at timestep \( t \) for an \( N \)-DoF robot.
Rather than considering net joint displacement between the start and end states, we compute the cumulative joint rotation distance along the trajectory:
</p>

<p class="math-display">
\[
E_{\mathrm{joint}}
=
\sum_{t=2}^{T}
\left\lVert
\boldsymbol{\theta}_t - \boldsymbol{\theta}_{t-1}
\right\rVert_1,
\]
</p>

<p>
where \( T \) denotes the trajectory length.
This metric captures the total amount of joint rotation required to execute a task,
penalizing unnecessary back-and-forth or oscillatory motions that may not affect task success
but reduce execution efficiency.
</p>

<p>
To account for differences in joint ranges and ensure comparability across joints,
we additionally report a normalized variant in which each joint rotation is scaled by its
allowable range:
</p>

<p class="math-display">
\[
E_{\mathrm{joint}}^{\mathrm{norm}}
=
\sum_{t=2}^{T}
\sum_{i=1}^{N}
\frac{
\left|
\theta_{t,i} - \theta_{t-1,i}
\right|
}{
\theta_i^{\max} - \theta_i^{\min}
},
\]
</p>

<p>
where \( \theta_i^{\min} \) and \( \theta_i^{\max} \) denote the lower and upper limits of joint \( i \).
Lower values indicate more efficient joint-space trajectories with reduced unnecessary rotation.
</p>

<!-- 4.7 Energy Efficiency  -->
    <div class="section-subtitle" id="EnergyEfficiency">Energy Efficiency.</div>
    
    <div class="section">
    <p>
We evaluate energy efficiency using a trajectory-level energy metric computed from joint torques and velocities available in simulation.
Specifically, the total trajectory energy \( E_{\text{traj}} \) is estimated by integrating mechanical power, electrical loss,
and constant overhead terms over time using a simplified actuator energy model.
To decouple energy consumption from execution length, we report normalized energy defined as
\( E_{\text{norm}} = \frac{E_{\text{traj}}}{T} \).
</p>

    </div> 



  </div> <!-- End of main-content div -->


  <div class="footer">
    <!-- © UC Berkeley | Powered by vision, motion, and a little ambition. -->
    <!-- © 2025 Youngjin Hong | Built using code inspired by the <a href="https://www.videomimic.net/" target="_blank">VideoMimic project</a>  (UC Berkeley). -->
    Built using code inspired by the <a href="https://www.videomimic.net/" target="_blank">VideoMimic</a> project (UC Berkeley).
  
  </div>

  <!-- Teaser Video Autoplay with Delay and Loop -->
  <script>
  document.addEventListener('DOMContentLoaded', function() {
    const video = document.getElementById('teaser-video');
    // const initialDelay = 1000; // No longer needed, autoplay attribute handles initial play
    const loopDelay = 3000;    // 3 seconds delay before looping

    // let initialPlayTimeout; // No longer needed
    let loopTimeout;

    if (video) {
      // Ensure video is muted (already in HTML, but good practice)
      video.muted = true;
      // Controls are already in HTML, ensuring user can play if autoplay fails

      // REMOVE JavaScript-based initial play:
      /*
      initialPlayTimeout = setTimeout(function() {
        video.play().then(function() {
          // Autoplay started
        }).catch(function(error) {
          console.log('Initial autoplay prevented for teaser video. User interaction might be needed.', error);
          video.controls = true; // Ensure controls are visible
        });
      }, initialDelay);
      */

      // Loop with delay - this part can stay
      video.addEventListener('ended', function() {
        clearTimeout(loopTimeout); 
        loopTimeout = setTimeout(function() {
          video.currentTime = 0; 
          video.play().catch(function(error) {
            console.log('Delayed loop play prevented for teaser video:', error);
          });
        }, loopDelay);
      });

      // --- Clear Timeouts on Manual Pause ---
      video.addEventListener('pause', function() {
        if (!video.ended && video.currentTime > 0) {
           // clearTimeout(initialPlayTimeout); // No longer needed
           clearTimeout(loopTimeout);
           console.log('Teaser video: Manual pause detected, clearing loop timeout.');
        }
      });

      // --- Clear Timeouts on Manual Play (if paused before initial delay finishes) ---
       video.addEventListener('play', function() {
           // if (initialPlayTimeout) { // No longer needed
           //     clearTimeout(initialPlayTimeout);
           // }
       });

    } else {
      console.error('Video element with ID "teaser-video" not found.');
    }
  });
  </script>

  <!-- JavaScript for Video Gallery Navigation -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const galleries = [
        {
          sectionId: 'simGallerySection', // ID of the .video-gallery-section for sim
          galleryInnerId: 'videoGallerySim',
          scrollLeftBtnId: 'scrollLeftBtnSim',
          scrollRightBtnId: 'scrollRightBtnSim'
        },

        {
          sectionId: 'realRelGallerySection', // ID of the .video-gallery-section for real-relative
          galleryInnerId: 'videoGalleryRealRel',
          scrollLeftBtnId: 'scrollLeftBtnRealRel',
          scrollRightBtnId: 'scrollRightBtnRealRel'
        },
        {
          sectionId: 'realAbsGallerySection', // ID of the .video-gallery-section for real-absolute
          galleryInnerId: 'videoGalleryRealAbs',
          scrollLeftBtnId: 'scrollLeftBtnRealAbs',
          scrollRightBtnId: 'scrollRightBtnRealAbs'
        },
        {
          sectionId: 'realFailGallerySection', // ID of the .video-gallery-section for real-fail
          galleryInnerId: 'videoGalleryRealFail',
          scrollLeftBtnId: 'scrollLeftBtnRealFail',
          scrollRightBtnId: 'scrollRightBtnRealFail'
        },
        
        {
          sectionId: 'reconstructionGallerySection', // ID of the .video-gallery-section for reconstruction
          galleryInnerId: 'videoGalleryReconstruction',
          scrollLeftBtnId: 'scrollLeftBtnReconstruction',
          scrollRightBtnId: 'scrollRightBtnReconstruction'
        }
      ];

      galleries.forEach(galleryConfig => {
        const gallerySection = document.getElementById(galleryConfig.sectionId);
        if (!gallerySection) {
          console.error(`Gallery section with ID ${galleryConfig.sectionId} not found.`);
          return;
        }

        const galleryContainer = gallerySection.querySelector('.video-gallery-container');
        const galleryInner = document.getElementById(galleryConfig.galleryInnerId);
        const scrollLeftBtn = document.getElementById(galleryConfig.scrollLeftBtnId);
        const scrollRightBtn = document.getElementById(galleryConfig.scrollRightBtnId);

        if (galleryContainer && galleryInner && scrollLeftBtn && scrollRightBtn) {
          // Calculate the scroll amount based on the width of the first video + gap
          const scrollAmount = (galleryInner.firstElementChild?.offsetWidth || 1280) + 15; // 15 is the gap

          scrollLeftBtn.addEventListener('click', () => {
            // Scroll the CONTAINER element
            galleryContainer.scrollBy({ left: -scrollAmount, behavior: 'smooth' });
          });

          scrollRightBtn.addEventListener('click', () => {
            // Scroll the CONTAINER element
            galleryContainer.scrollBy({ left: scrollAmount, behavior: 'smooth' });
          });

          /* --- REMOVE OR COMMENT OUT HOVER LOGIC ---
          // Optional: Add hover-to-play functionality for gallery videos
          // Target videos within galleryInner
          const galleryVideos = galleryInner.querySelectorAll('.gallery-video');
          galleryVideos.forEach(video => {
              video.addEventListener('mouseenter', () => {
                  video.play().catch(e => console.log("Autoplay prevented:", e));
              });
              video.addEventListener('mouseleave', () => {
                  video.pause();
                  // video.currentTime = 0; // Optional: reset video on mouse leave
              });
          });
          */ // --- END OF REMOVED HOVER LOGIC ---

        } else {
          console.error(`Gallery elements not found for navigation setup in section ${galleryConfig.sectionId}.`);
          // Log which elements might be missing
          if (!galleryContainer) console.error('Missing element: .video-gallery-container in section ' + galleryConfig.sectionId);
          if (!galleryInner) console.error(`Missing element with ID ${galleryConfig.galleryInnerId}`);
          if (!scrollLeftBtn) console.error(`Missing element with ID ${galleryConfig.scrollLeftBtnId}`);
          if (!scrollRightBtn) console.error(`Missing element with ID ${galleryConfig.scrollRightBtnId}`);
        }
      });
    });
  </script>

  <!-- JavaScript to prevent default click on specific image links -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const imageLinkIds = ['figure-1-img', 'figure-2-img', 'figure-3-img', 'figure-4-img'];
      imageLinkIds.forEach(id => {
        const linkElement = document.getElementById(id);
        if (linkElement) {
          linkElement.addEventListener('click', function(event) {
            event.preventDefault();
          });
        }
      });
    });
  </script>

</body>
</html>
